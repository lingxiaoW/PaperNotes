# RL Algorithms

## Transformer Based RL

- **Decision Transformer Reinforcement Learning via Sequence Modeling**
 **[`arXiv 2021`]** *Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, Igor Mordatch* [(arXiv)](http://arxiv.org/abs/2106.01345) [(pdf)](./Decision%20Transformer%20-%20Reinforcement%20Learning%20via%20Sequence%20Modeling.pdf) (Citation: 686)

- **Q-Transformer: Scalable Offline Reinforcement Learning via Autoregressive Q-Functions** [(pdf)](./Q-transformer.pdf) (Citation: 480)


## Deep RL Algorithms

- **Addressing Function Approximation Error in Actor-Critic Methods**
 **[`ICML 2018`]** *Scott Fujimoto, Herke van Hoof, David Meger* [(arXiv)](http://arxiv.org/abs/1802.09477) [(pdf)](./Addressing%20Function%20Approximation%20Error%20in%20Actor-Critic%20Methods.pdf)(Citation: 3945)

 - **Continuous control with deep reinforcement learning**
 **[`arXiv 2015`]** *Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra* [(arXiv)](http://arxiv.org/abs/1509.02971) [(pdf)](./Continuous%20control%20with%20deep%20reinforcement%20learning.pdf) (Citation: 13311)


 - **Deterministic Policy Gradient Algorithms** **[`ICML 2014`]** *Silver David, et al.*[(ICML)](http://proceedings.mlr.press/v32/silver14.pdf)[(pdf)](./Deterministic%20Policy%20Gradient%20Algorithms.pdf)(Citation: 4244)

- **Domain Adaptation for Reinforcement Learning on the Atari**
 **[`arXiv 2018`]** *Thomas Carr, Maria Chli, George Vogiatzis* [(arXiv)](http://arxiv.org/abs/1812.07452) [(pdf)](./Domain%20adaptation%20for%20reinforcement%20learning%20on%20atari.pdf) (Citation: 28)

- **Memory-based control with recurrent neural networks**
 **[`NIPS 2015`]** *Nicolas Heess, Jonathan J Hunt, Timothy P Lillicrap, David Silver* [(arXiv)](http://arxiv.org/abs/1512.04455) [(pdf)](./Memory-based%20control%20with%20recurrent%20neural%20networks.pdf) (Citation: 309)

 - **Memory-based Deep Reinforcement Learning for POMDPs**
 **[`arXiv 2021`]** *Lingheng Meng, Rob Gorbet, Dana Kulić* [(arXiv)](http://arxiv.org/abs/2102.12344) [(pdf)](./Memory-based%20Deep%20Reinforcement%20Learning%20for%20POMDPs.pdf) (Citation: 53)
    - Most deep reinforcement learning works focus on developing algorithms for MDP and few works consider the more complex POMDP, where the observation is just a partial representation of the underlying state. 
    - POMDPs have been tackled with the concept of belief state, which represents the agent's current belief about the possible physical states it might be in, given the sequence of actions and observations up to that point. 

 - **Muesli Combining Improvements in Policy Optimization**
 **[`arXiv 2021`]** *Matteo Hessel, Ivo Danihelka, Fabio Viola, Arthur Guez, Simon Schmitt, Laurent Sifre, Theophane Weber, David Silver, Hado van Hasselt* [(arXiv)](http://arxiv.org/abs/2104.06159) [(pdf)](./Muesli%20-%20Combining%20Improvements%20in%20Policy%20Optimization.pdf) (Citation: 58)

 - **Rainbow Combining Improvements in Deep Reinforcement Learning**
 **[`AAAI 2018`]** *Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, David Silver* [(arXiv)](http://arxiv.org/abs/1710.02298) [(pdf)](./Rainbow%20-%20Combining%20Improvements%20in%20Deep%20Reinforcement%20Learning.pdf) (Citation: 2154)

- **Deep Recurrent Q-Learning for Partially Observable MDPs**
 **[`arXiv 2015`]** *Matthew Hausknecht, Peter Stone* [(arXiv)](http://arxiv.org/abs/1507.06527) [(pdf)](./Recurrent%20DQN.pdf) (Citation: 1886)

 - **Recurrent Experience Replay in Distributed Reinforcement Learning****[`ICLR 2018`]** *Steven Kapturowski, Georg Ostrovski, Will Dabney, John Quan, Rémi Munos* [(OpenReview)](https://openreview.net/pdf?id=r1lyTjAqYX)[(pdf)](./RECURRENT%20EXPERIENCE%20REPLAY%20IN%20DISTRIBUTED%20REINFORCEMENT%20LEARNING.pdf)

- **Revisiting Fundamentals of Experience Replay**
 **[`ICML 2020`]** *William Fedus, Prajit Ramachandran, Rishabh Agarwal, Yoshua Bengio, Hugo Larochelle, Mark Rowland, Will Dabney* [(arXiv)](http://arxiv.org/abs/2007.06700) [(pdf)](./Revisiting%20Fundamentals%20of%20Experience%20Replay.pdf) (Citation: 185)

 - **Soft Actor-Critic Off-Policy Maximum Entropy Deep Reinforcement
  Learning with a Stochastic Actor**
 **[`ICML 2018`]** *Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine* [(arXiv)](http://arxiv.org/abs/1801.01290) [(pdf)](./Soft%20Actor-Critic%20Off-Policy%20Maximum%20Entropy%20Deep%20Reinforcement%20Learning%20with%20a%20Stochastic%20Actor.pdf) (Citation: 6088)

 - **Offline Reinforcement Learning with Implicit Q-Learning**
 **[`arXiv 2021`]** *Ilya Kostrikov, Ashvin Nair, Sergey Levine* [(arXiv)](http://arxiv.org/abs/2110.06169) [(pdf)](./implicit%20Q%20leanring.pdf) (Citation: 467)













